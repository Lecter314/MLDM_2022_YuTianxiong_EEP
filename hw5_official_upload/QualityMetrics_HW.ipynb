{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/MLDM-2022/blob/master/06-model-evaluation/QualityMetrics_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ij_zY4soDF2Z"
   },
   "source": [
    "# Cross-validation riddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUCsY5OlDJPl"
   },
   "source": [
    "Here's a small example of cross-validation done wrongly. Can you spot the problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mSUzkXsC-R4H"
   },
   "outputs": [],
   "source": [
    "# Some imports...\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyDp3Xc_DaDM"
   },
   "source": [
    "**Plan:**\n",
    "\n",
    "- Let's create a binary classification dataset where targets are completely independent from the features\n",
    "  - *(i.e. no model could ever predict them well)*\n",
    "- We'll do some simple feature selection\n",
    "- And cross-validate a model on this data\n",
    "\n",
    "**Q:** what accuracy do we expect (classes are even)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHx51DKP8Rcf"
   },
   "source": [
    "We'll start from writing a class to select the best features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rRNmKZJJ8W7x"
   },
   "outputs": [],
   "source": [
    "class FeatureSelector:\n",
    "  def __init__(self, num_features):\n",
    "    self.n = num_features # number of best features to select\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    # Select features that describe the targets best, i.e. have\n",
    "    # highest correlation with them:\n",
    "    covariance = ((X - X.mean(axis=0)) * (y[:,np.newaxis] - y.mean())).mean(axis=0)\n",
    "    self.best_feature_ids = np.argsort(np.abs(covariance))[-self.n:]\n",
    "    return self.best_feature_ids\n",
    "\n",
    "  def transform(self, X):\n",
    "    return X[:,self.best_feature_ids]\n",
    "\n",
    "  def fit_transform(self, X, y):\n",
    "    self.fit(X, y)\n",
    "    return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6mu9gHgNBk_V",
    "outputId": "b2ca1fe5-90ae-4792-d193-9dc51f460382"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.8600000000000001\n"
     ]
    }
   ],
   "source": [
    "num_features_total = 1000\n",
    "num_features_best = 100\n",
    "\n",
    "N = 100\n",
    "\n",
    "# Dataset generation\n",
    "X = np.random.normal(size=(N, num_features_total))\n",
    "y = np.random.randint(2, size=N)\n",
    "\n",
    "# Feature selection:\n",
    "X_best = FeatureSelector(num_features_best).fit_transform(X, y)\n",
    "\n",
    "# Simple classification model\n",
    "model = LinearSVC()\n",
    "\n",
    "# Estimatin accuracy using cross-validation:\n",
    "cv_score = cross_val_score(model, X_best, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
    "print(f\"CV score is {cv_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afadN3ZVFKjF"
   },
   "source": [
    "What's going on?! Why accuracy is so high?\n",
    "\n",
    "Maybe it just happened by chance? Let's repeat this experiment many times and histogram the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "QDbOMXnuC6uw",
    "outputId": "0722aeed-f580-406b-d93b-729581edb8ec"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_features_total = 1000\n",
    "num_features_best = 100\n",
    "\n",
    "N = 100\n",
    "def experiment():\n",
    "  # Dataset generation\n",
    "  X = np.random.normal(size=(N, num_features_total))\n",
    "  y = np.random.randint(2, size=N)\n",
    "\n",
    "  # Feature selection:\n",
    "  X_best = FeatureSelector(num_features_best).fit_transform(X, y)\n",
    "\n",
    "  # Simple classification model\n",
    "  model = LinearSVC()\n",
    "\n",
    "  # Estimatin accuracy using cross-validation:\n",
    "  return cross_val_score(model, X_best, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
    "\n",
    "results = [experiment() for _ in range(100)]\n",
    "plt.hist(results, bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMYRjjqOLB5Z"
   },
   "source": [
    "## Task 1 (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bLaEypoF5pb"
   },
   "source": [
    "Explain why the estimated model accuracy is not 50% on a dataset where targets were generated **independently from the features (!!!)**.\n",
    "\n",
    "Find and fix the problem (don't change the dataset generation or its parameters - `num_features_total`, `num_features_best`, `N`).\n",
    "\n",
    "*Hint: the problem is in the overall logic, and not a bug in the code.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "Very interesting, firstly I didn't buy the *hint* and took some time checking whether there're some logic errors beneath coding and turned out there aren't. Then I try to find the overall logic error, and I have to say that's so counterintuitive. Basically, the model knows something that it shouldn't know beforehand, during the process of Feature Selecting. When applied the feature selection we used information from both the training set and the test sets for the cross-validation, in this case, the correlation values. In fact, when calculating Accuracy in the i-th iteration of cross-validation should be using only the information on the training fold, and nothing should come from the test fold.\n",
    "\n",
    "I also find good illustration in https://github.com/mottalrd/cross-validation-done-wrong, with decent graphs, so what we did wrong is like the graph below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cv_example_wrong.png\" width=\"80%\" height=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it should be like:\n",
    "\n",
    "<img src=\"cv_example_right.png\" width=\"80%\" height=\"80%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EfT36WPTLyqB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "accuracy = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    best_feature_ids = FeatureSelector(num_features_best).fit(X_train, y_train)\n",
    "    X_train_best = FeatureSelector(num_features_best).fit_transform(X_train, y_train)\n",
    "    X_test_best = X_test[:,best_feature_ids]\n",
    "    \n",
    "    model = LinearSVC()\n",
    "    model.fit(X_train_best, y_train)\n",
    "    \n",
    "    pred = model.predict(X_test_best)\n",
    "    accuracy.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "mean_accuracy = np.mean(accuracy)\n",
    "round(mean_accuracy,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it looks reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's come back to Task 3 *(task 1 I guess?)* of Data Handling HW.\n",
    "Build a model with KNeighborsClassifier to get a higher accuracy on 5-fold Cross Validation than you achieve using your previosly fitted model (you can just copy the params from the previous notebook). \n",
    "\n",
    "Use `sklearn.model_selection.GridSearchCV` to find best parameters.  You may check the parameters'  description as follows:\n",
    "``` python\n",
    "help(KNeighborsClassifier)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train.csv'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "url = \"https://raw.githubusercontent.com/HSE-LAMBDA/MLDM-2022/main/01-intro/train.csv\"\n",
    "wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "data = pd.read_csv(\"train.csv\", index_col='PassengerId')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From previous work we got an accuracy of 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "# previous code from Data Handling HW\n",
    "def feature_selection_and_preprocessing(dataset):\n",
    "    # <YOUR CODE>\n",
    "    features = dataset.copy()\n",
    "    features = features[[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\"]]\n",
    "    features[\"Age\"] = features[\"Age\"].fillna(features[\"Age\"].median())\n",
    "    features[\"Sex\"].replace({\"female\": 0,\"male\": 1}, inplace=True)\n",
    "    features[[\"Age\",\"SibSp\",\"Parch\"]] = features[[\"Age\",\"SibSp\",\"Parch\"]].apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "    return features\n",
    "\n",
    "\n",
    "model = KNeighborsClassifier(\n",
    "    # <YOUR CODE>\n",
    "    n_neighbors=3\n",
    ")\n",
    "\n",
    "# Validation code (do not touch)\n",
    "data_train = data.iloc[:-100]\n",
    "data_test = data.iloc[-100:]\n",
    "\n",
    "model.fit(\n",
    "    feature_selection_and_preprocessing(\n",
    "        data_train.drop('Survived', axis=1)\n",
    "    ),\n",
    "    data_train['Survived']\n",
    ")\n",
    "\n",
    "test_predictions = model.predict(\n",
    "    feature_selection_and_preprocessing(\n",
    "        data_test.drop('Survived', axis=1)\n",
    "    )\n",
    ")\n",
    "print(\"Test accuracy:\", accuracy_score(\n",
    "    data_test['Survived'],\n",
    "    test_predictions\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `sklearn.model_selection.GridSearchCV` to find best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'leaf_size': [i for i in range(20,40)],\n",
    "        'n_neighbors': [i for i in range(11)],\n",
    "        'p': [i for i in range(5)]\n",
    "        }\n",
    "\n",
    "model4clf = KNeighborsClassifier()\n",
    "clf = GridSearchCV(model4clf, parameters, scoring='accuracy', n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2200 candidates, totalling 11000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 4800 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 9328 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 11000 out of 11000 | elapsed:   26.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'leaf_size': [20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
       "                                       30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "                         'n_neighbors': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'p': [0, 1, 2, 3, 4],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(\n",
    "    feature_selection_and_preprocessing(\n",
    "        data_train.drop('Survived', axis=1)\n",
    "    ),\n",
    "    data_train['Survived']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "knn_best = clf.best_estimator_\n",
    "test_predictions = knn_best.predict(\n",
    "    feature_selection_and_preprocessing(\n",
    "        data_test.drop('Survived', axis=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Test accuracy:\", accuracy_score(\n",
    "    data_test['Survived'],\n",
    "    test_predictions\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As seen, we got an improvement in Test accuracy, best estimators is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(leaf_size=20, n_neighbors=4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "QualityMetrics_HW.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
